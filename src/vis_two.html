<head xmlns="http://www.w3.org/1999/html">
    <script src="https://cdn.jsdelivr.net/npm/vega@5"></script>
    <script src="https://cdn.jsdelivr.net/npm/vega-lite@5"></script>
    <script src="https://cdn.jsdelivr.net/npm/vega-embed@6"></script>
    <title>Question 2</title>
</head>

<body style="background-color:#121212;padding-left: 10%; font-family:verdana">
<div id="my_info" style="color: #ffffff">
    <b><u>Name: </u></b> Jack Geraghty <br/>
    <b><u>Student Number: </u></b> 16384181 <br/>
    <b><u>Email: </u></b> jack.geraghty@ucdconnect.ie <br/>
    <b><u>Dataset: </u></b> Spotify Dataset<br/>
    <b><u>Initial Questions</u>:</b> How have the features that make up music changed over time? How do these features
    make up
    the music we listen to?
</div>
<hr style="color: white">

<div id="vis" style="color: black;width: 90%;height: 65%; color: black"></div>
<br/><br/><br/><br/>


<div id="answer" style="background-color: #121212;width: 90%;color: #ffffff">
    <label for="option">Use Median: </label>
    <input type="checkbox" id="option" name="avg_option" value="Use Median" onclick="visualize()">
    <br/>
    <hr style="color: white">
    <u><b>Chart Specific Question: </b></u>
    <p>
       How do the genres present in the dataset use each of the musical features?
    </p>

    <hr style="color: white">

    <u><b>Description: </b></u>
    <p>
        The chart shows the breakdown of each of the musical features per genre. The feature values are aggregated by
        either
        mean or median, it is possible to switch between these different methods of aggregation by using the "Use
        Median"
        checkbox, which is available just beneath the chart.
        The musical features used in this chart and in the others are represented as a score between 0.0 and 1.0.
        To enable easier comparison of the same features across the
        genres there is an additional text mark to show the exact value of the bar to the right of each bar. It is also
        possible
        to select a feature and highlight it and the same feature across all genres by clicking a bar. To undo this,
        simply
        click anywhere on the chart that isn't a bar.
    </p>
    <p>
        The chart utilises sorting, this sorting is based on either the mean or median (whichever is being used) of the
        feature values across the multiple charts.
    </p>
    <hr style="color: white">

    <u><b>Insight: </b></u>
    <p>
        This chart gives insight into how each of the main genres present in the dataset utilise each of the musical
        features.
        Some of these were expected, e.g. that EDM would have a high value for energy and danceabilty, and others were
        not, e.g. based on this data R&B music is relatively acoustic compared to the other genres.
    </p>
    <p>
        It doesn't come as a surprise that the two genres with the highest levels of energy are from the EDM
        (Electronic Dance Music) and Rock genres, electronic music in general is quite fast paced and utilises synthetic
        sounds which are energetic in nature, while Rock music also makes heavy use of energetic instruments such as
        drums and electric guitars. They are both fast paced and make use of a multitude of different sounds and
        instruments which are designed to invigorate and energise a crowd.
    </p>

    <p>
        Originally I would have assumed that all of the genres present would be quite energetic in
        nature, and while all of them having energy values of greater than 0.55 there are two outliers present relative
        to the other genres, they are R&B and rap. Rhythm & Blues (R&B) originated in the 1940s and historically is
        based on a mix of rock and jazz based music. It has since changed and evolved into a more modern version of
        itself with artists such as Drake contributing to the genre. However I would have expected it to still maintain
        quite a high level of energy since both rock and jazz music (rock being present in this chart) are energetic
        in nature.
    </p>
    <p>
        Rap is another genre which I would have expected to have a high value for energy. However, after
        investigating the genre more during this assignment I am less surprised its value. Rap consists of a stylised
        rhythmic music which is accompanied by rhythmic and rhyming speech. Rap has the highest level of speechiness
        out of the genres by a large enough margin and it is possible that because of this more "speechy" nature that
        the energy value is lower than expected, to ensure that lyrics are communicated clearly and in time with the
        rhythmic nature of the accompanying music.
    </p>

    <p>
        Comparing the genres measure of danceability leads to some surprising insight. Based off of the data in the dataset
        the most danceable music is Rap, followed by the Latin and R&B genres. Initally I thought this might have been an
        issue with the dataset but after investigating I found that there was a sufficient number of entries from the
        these genres. Unsurprisingly, Latin music is very danceable, this lines up with it's general composition which shows
        Latin music to be energetic, moderately fast paced(tempo) and positive(valence) in nature. I was most surprised by
        the low danceability score of the EDM genre, this is a genre which has dance in it's name. Danceability is described
        in the dataset as a combination of features such as tempo, rhythm stability, beat strength and overall regularity.
        These are things which I would have assumed the EDM genre would adhere to.
    </p>

    <p>
        A feature of EDM which was expected to be quite high was that of instrumentalness. There are some potential issues
        with this measure though in the dataset, depending on whether or not you use the mean or median you get different
        results. This is more than likely caused by the overall low value of instrumentalness across the entire dataset which
        results in low values if the median is selected as the aggregation of choice. Using the mean however as a method
        of comparison the chart shows the EDM is significantly more instrumental compared to the other genres. This is
        expected as a lot of EDM doesn't make use of lyrics and relies mostly on synthetic instruments.
    </p>
    <p>
        Another surprising feature is acousticness, it has low values for the genres of EDM and Rock, but has surprisingly
        high values (relative to the other genres) for both R&B and Rap. I would have assumed that these genres would have
        relied more on beats compared acoustic sounds and was especially surprised that R&B has the highest level of
        acousticness.
    </p>
    <p>
        There is more than can be taken from this graph, but I felt that the above covers all of the most interesting
        comparisons that I was able to make.
    </p>
    <hr style="color: white">
    <u><b>Design Considerations: </b></u>
    <p>
        I used a small multiples bar chart to present the breakdown of the musical features per genre. Bar charts are
        a simple, yet highly effective way of conveying quantitative information that also has a nominal aspect to it.
        The order in which features are displayed is sorted based on either the mean or median of the feature, in
        descending order. The small multiples approach interferes with this sorting slightly. The resulting ordering of
        features is used as a common axis across the rows of the chart, so the actual ordering of the bars per chart
        doesn't
        look sorted for all charts. An example of this is the features "instrumentalness" and "speechiness", when using
        the default
        aggregation, the mean, "instrumentalness" is last in the ordering with "speechiness" just above it. Their means
        are 0.0933 and 0.10645 respectively across all charts, hence the ordering.
    </p>
    <p>
        I opted to use small multiples as it is a cleaner way of inviting comparison across the genres compared to using
        a single chart to display all bars for all genres. To present the information in such a way, different colours
        and
        a legend would be required to differentiate between the genres. This would require more effort from the reader
        to
        interpret compared to using a small multiples chart, all of which have a common x and y axis.
    </p>
    <p>
        The chart originally had a tooltip that would display information when hovering over a bar. This was before I
        implemented the ability to highlight a feature by selecting one of its bars. The tooltip didn't enable an easy
        comparison of a features value across genres so I decided that the highlighting feature, alongside an additional
        text mark showing the value of the bar would be easier for the reader to interpret.
    </p>
    <p>
        Originally, I wanted to use a radar chart to present this information. Radar charts are useful
        for showing the composition of something when there are several parameters that contribute to the overall make
        up.
        The axes of a radar chart can become a problem if the factors all have different max values. This issue was
        fixed
        though by having all musical features normalized between 0 and 1. Radar charts also become quite difficult to
        read
        and interpret once several variables are being displayed. This was the case with trying to present feature
        composition
        per genre, it would end up being a blur of overlapping lines with the reader trying to match up colours from a
        legend
        to lines on the chart. Radar charts also don't utilize any meaningful ordering to the variables around the
        chart.
        This can lead readers to putting more importance on different variables even though there is no variable that is
        considered more important. The area of a radar chart, that is the area made up by the connected lines, increases
        in a squared fashion as opposed to linearly. This results in small changes having a larger impact on the area
        created by the chart, which can lead to the reader thinking that these small changes have more of an impact than
        they really do.
    </p>
    <p>
        An alternative to using a single radar chart would be to use a small multiples variation of
        it. Each chart would depict a single genre and the reader could then compare each chart against the others. This
        still has some of the issues mentioned above, but it is definitely a better alternative. An issue I encountered
        with
        small multiples of a radar chart is that radar charts are only available in the Vega specification and not in
        Vega-Lite. It was relatively straight forward to create a single radar chart, but expanding it to small
        multiples
        proved very difficult. In the end I thought the extra work and the availability of other charts (which have the
        same if not better expressive power and better ease of understanding compared to radar charts) wasn't enough to
        use a small multiples radar chart in the end.
    </p>
    <p>
        Another alternative, that ultimately was not used, was a Parallel Coordinates chart. Each parallel bar would
        have
        been a feature found in the dataset, with the bar having a scale of 0 to 1. Then each genre would have been
        represented using a different coloured line. The main advantage of using a Parallel Coordinates chart would be
        its
        ability to represent n-dimensional data in a 2-dimensional space. Another advantage is that the parallel bars
        can be reordered to explore relations between dimensions. This advantage can also be a disadvantage as it means
        that there can be a preferred arrangement of the bars that best suits what the aim of the chart is. This isn't
        an
        easy arrangement to find and often requires the use of some heuristics to achieve some sort of preference in the
        ordering. A significant disadvantage of a Parallel Coordinates chart is that a lot of people aren't familiar
        with
        them, and because of this they can easily confuse the reader of the chart.
    </p>
    <p>
        In the end I thought that using a small multiples bar chart was the best chart to use to present this
        information.
        Bar charts are simple and incredibly easy to understand, a quality lacking in the alternatives I discussed.
    </p>
    <hr style="color: white">

    <u><b>Data Filtering/Aggregation/Transforms: </b></u>
    <p>
        This chart makes use of the general filtering done in the previous question, that is filtering out duplicates,
        NaNs and infinity values, and also dropping duplicate entries from the dataset.
    </p>
    <p>
        Two of the features, tempo and loudness have been normalised to be
        between 0 and 1. This was done so as to enable them to be plotted using the same scale as the other features.
        Loudness, as per the dataset description, typically ranges between -60dB and 0dB. Before normalizing I took the
        absolute value of loudness so it could then be plotted in the same way as the other features. There wasn't any
        ranges given for the tempo feature. This makes sense as tempo is the measure of the Beats per Minute(BPM) of a
        track,
        and as such an upper bound can't easily be determined. To overcome this I used the minimum and maximum values of
        tempo in the dataset when normalising. This isn't perfect but it does give an approximate value of tempo in the
        dataset.
    </p>
    <p>
        The dataset used is a modified version of the original, it is available on
        <a href="https://raw.githubusercontent.com/JackGeraghty/Info_Vis/master/data/q2.csv">GitHub</a> for inspection.
        This version of the dataset has the following columns, playlist_genre, feature, median, mean. The median and
        mean
        were calculated for each of the features present in the dataset, excluding mode, the type of scale
        used(major/minor) and key, the estimated overall key of the track. Mode was excluded as it didn't contribute to
        the aim of chart. The key of a track was also excluded as it uses a non-standard range compared to the rest of
        the
        features. The key value for a track corresponds to a pitch value using standard Pitch Class notation. This
        notation
        is something that only someone who has some education in music theory would be able to fully appreciate and
        interpret
        and because of this I felt that it didn't help with answering the question posed and would only confuse the
        reader
        of the chart.
    </p>

    <hr style="color: white">
    <hr style="color: white">

    <p>
        All work is my own, Jack Geraghty - 16384181
    </p>

    <hr style="color: white">
</div>

<script type="text/javascript">
    window.addEventListener("resize", visualize);
    visualize();

    function visualize() {
        const w = Math.floor(window.innerWidth * 0.25);
        const h = Math.floor(window.innerHeight * 0.275)

        const averageToUse = document.getElementById("option").checked ? "median" : "mean";
        const capitalizedAvgToUse = averageToUse.charAt(0).toUpperCase() + averageToUse.slice(1);

        const data = {
            "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
            "data": {"url": "https://raw.githubusercontent.com/JackGeraghty/Info_Vis/master/data/q2.csv"},
            "facet": {
                "field": "playlist_genre", "header": {
                    "title": `How Genres Make Use of Musical Features - Using ${capitalizedAvgToUse}`,
                    "titleFontSize": 20, "labelFontSize": 15
                }
            },
            "spec": {
                "layer": [{
                    "selection": {
                        "feature_selection": {"type": "multi", "fields": ["feature"]}
                    },
                    "mark": "bar"
                }, {
                    "mark": {
                        "type": "text",
                        "align": "left",
                        "baseline": "middle",
                        "dx": 3
                    },
                    "encoding": {
                        "text": {"field": averageToUse, "type": "quantitative"}
                    }
                }],
                "encoding": {
                    "x": {
                        "field": averageToUse,
                        "title": `${capitalizedAvgToUse} Feature Value`,
                        "type": "quantitative",
                        "scale": {"domain": [0, 1]},
                        "axis": {"tickCount": 20}
                    },
                    "y": {
                        "field": "feature",
                        "type": "nominal",
                        "title": "Musical Feature",
                        "sort": {"field": averageToUse, "op": averageToUse, "order": "descending"}
                    },
                    "color": {
                        "condition": {
                            "selection": "feature_selection",
                            "type": "nominal",
                            "legend": null
                        },
                        "value": "grey"
                    },
                    "opacity": {
                        "condition": {
                            "selection": "feature_selection",
                            "value": 1
                        },
                        "value": 0.1
                    }
                },
                "width": w,
                "height": h
            },
            "columns": 3

        };
        vegaEmbed("#vis", data);
    }
</script>
</body>